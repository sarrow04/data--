import streamlit as st
import pandas as pd
import io

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(
    page_title="ãƒ‡ãƒ¼ã‚¿çµåˆãƒ»åˆ†å‰²ãƒ„ãƒ¼ãƒ« for Time Series",
    page_icon="ğŸ”—",
    layout="wide"
)

# --- é–¢æ•° ---
def convert_df_to_csv(df):
    """DataFrameã‚’CSVå½¢å¼ã®ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›ã™ã‚‹ (æ–‡å­—åŒ–ã‘å¯¾ç­–æ¸ˆã¿)"""
    return df.to_csv(index=False).encode('utf-8-sig')

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
st.title("ğŸ”— CSVãƒ‡ãƒ¼ã‚¿ çµåˆ/åˆ†å‰²ãƒ„ãƒ¼ãƒ« (æ™‚ç³»åˆ—åˆ†æå¯¾å¿œç‰ˆ)")
st.write("2ã¤ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®‰å…¨ã«çµåˆã—ã€æ—¥ä»˜ç‰¹å¾´é‡ã®ç”Ÿæˆãªã©ã‚’è¡Œã£ãŸå¾Œã€å†ã³å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã«åˆ†å‰²ã§ãã¾ã™ã€‚")

# --- session_stateã®åˆæœŸåŒ– ---
if 'combined_df' not in st.session_state:
    st.session_state.combined_df = None

# --- ã‚¿ãƒ–ã§æ©Ÿèƒ½ã‚’åˆ†å‰² ---
tab1, tab2 = st.tabs(["Step 1: ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆãƒ»åŠ å·¥ã™ã‚‹", "Step 2: ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã™ã‚‹"])

# =====================================================================================
# Step 1: çµåˆæ©Ÿèƒ½
# =====================================================================================
with tab1:
    st.header("Step 1: çµåˆã¨ç‰¹å¾´é‡ç”Ÿæˆ")
    
    with st.expander("1. ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦çµåˆ", expanded=True):
        col1, col2 = st.columns(2)
        with col1:
            file1 = st.file_uploader("ãƒ•ã‚¡ã‚¤ãƒ«1 (ä¾‹: train.csv) ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"])
        with col2:
            file2 = st.file_uploader("ãƒ•ã‚¡ã‚¤ãƒ«2 (ä¾‹: test.csv) ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"])

        if file1 and file2:
            df1 = pd.read_csv(file1)
            df2 = pd.read_csv(file2)
            
            target_column = st.selectbox(
                'ç›®çš„å¤‰æ•°ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«1ã«ã—ã‹å­˜åœ¨ã—ãªã„åˆ—ï¼‰ãŒã‚ã‚Œã°é¸æŠã—ã¦ãã ã•ã„ã€‚',
                options=[None] + list(df1.columns)
            )
            
            # åˆ—åã®ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½
            df1_cols = set(df1.columns) - {target_column} if target_column else set(df1.columns)
            df2_cols = set(df2.columns)
            if df1_cols != df2_cols:
                st.warning("è­¦å‘Š: 2ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ—åï¼ˆç›®çš„å¤‰æ•°ã‚’é™¤ãï¼‰ãŒå®Œå…¨ã«ã¯ä¸€è‡´ã—ã¦ã„ã¾ã›ã‚“ã€‚")
                st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«1ã®ã¿ã®åˆ—:** `{list(df1_cols - df2_cols)}`")
                st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«2ã®ã¿ã®åˆ—:** `{list(df2_cols - df1_cols)}`")

            # å‡¦ç†å®Ÿè¡Œãƒœã‚¿ãƒ³
            if st.button("Step 1.1: ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆã™ã‚‹", use_container_width=True):
                # ã€Œåæœ­ã€ã¨ãªã‚‹åˆ—ã‚’è¿½åŠ 
                df1['source_dataset'] = file1.name
                df2['source_dataset'] = file2.name
                
                # ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆã—ã€session_stateã«ä¿å­˜
                combined_df = pd.concat([df1, df2], ignore_index=True, sort=False)
                st.session_state.combined_df = combined_df
                
                st.success("ãƒ‡ãƒ¼ã‚¿ã®çµåˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
                if target_column:
                    st.info(f"ğŸ’¡ ãƒ•ã‚¡ã‚¤ãƒ«2ç”±æ¥ã®è¡Œã§ã¯ã€ç›®çš„å¤‰æ•° '{target_column}' ãŒç©ºæ¬„ (NaN) ã«ãªã£ã¦ã„ã¾ã™ã€‚")
    
    # --- çµåˆãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ã€å¾Œç¶šå‡¦ç†ã®UIã‚’è¡¨ç¤º ---
    if st.session_state.combined_df is not None:
        st.markdown("---")
        st.subheader("çµåˆå¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.dataframe(st.session_state.combined_df.head())
        st.write(f"åˆè¨ˆè¡Œæ•°: {len(st.session_state.combined_df)}")

        ### --- æ”¹å–„ç‚¹: è‡ªå‹•ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°æ©Ÿèƒ½ --- ###
        st.markdown("---")
        with st.expander("2. (ã‚ªãƒ—ã‚·ãƒ§ãƒ³) æ—¥ä»˜åˆ—ã‹ã‚‰ç‰¹å¾´é‡ã‚’è‡ªå‹•ç”Ÿæˆ"):
            
            datetime_column = st.selectbox(
                "æ—¥ä»˜ãƒ»æ™‚åˆ»æƒ…å ±ãŒå«ã¾ã‚Œã‚‹åˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚",
                options=[None] + list(st.session_state.combined_df.columns)
            )
            
            if datetime_column:
                st.write("ä½œæˆã—ãŸã„ç‰¹å¾´é‡ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š")
                
                # ä½œæˆã™ã‚‹ç‰¹å¾´é‡ã®é¸æŠè‚¢
                features_to_create = {
                    "year": "å¹´", "month": "æœˆ", "day": "æ—¥",
                    "hour": "æ™‚", "minute": "åˆ†", "second": "ç§’",
                    "dayofweek": "æ›œæ—¥ (0=æœˆ, 6=æ—¥)", "dayofyear": "å¹´åˆã‹ã‚‰ã®æ—¥æ•°",
                    "weekofyear": "å¹´å†…ã®é€±ç•ªå·", "quarter": "å››åŠæœŸ"
                }
                
                selected_features = []
                cols = st.columns(4)
                for i, (feature, label) in enumerate(features_to_create.items()):
                    if cols[i % 4].checkbox(label, value=True): # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ON
                        selected_features.append(feature)

                if st.button("Step 1.2: æ—¥ä»˜ç‰¹å¾´é‡ã‚’ç”Ÿæˆã™ã‚‹", use_container_width=True):
                    df = st.session_state.combined_df.copy()
                    
                    # ç¢ºå®Ÿã«datetimeå‹ã«å¤‰æ›
                    df[datetime_column] = pd.to_datetime(df[datetime_column])
                    
                    # é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ã‚’ãƒ«ãƒ¼ãƒ—ã§ä½œæˆ
                    for feature in selected_features:
                        new_col_name = f"{datetime_column}_{feature}"
                        df[new_col_name] = getattr(df[datetime_column].dt, feature)
                        
                    # isocalendar().weekã¯ç‰¹åˆ¥æ‰±ã„
                    if 'weekofyear' in selected_features:
                         df[f"{datetime_column}_weekofyear"] = df[datetime_column].dt.isocalendar().week

                    st.session_state.combined_df = df
                    st.success("æ—¥ä»˜ç‰¹å¾´é‡ã®ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
                    st.dataframe(st.session_state.combined_df.head())

        st.markdown("---")
        st.download_button(
           label="åŠ å·¥æ¸ˆã¿CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
           data=convert_df_to_csv(st.session_state.combined_df),
           file_name='processed_combined_data.csv',
           mime='text/csv',
           use_container_width=True
        )

# =====================================================================================
# Step 2: åˆ†å‰²æ©Ÿèƒ½
# =====================================================================================
with tab2:
    st.header("Step 2: åˆ†å‰²")
    st.info("Step 1ã§åŠ å·¥ãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸã€çµåˆæ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    
    processed_file = st.file_uploader("åŠ å·¥æ¸ˆã¿ã®çµåˆãƒ‡ãƒ¼ã‚¿ ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"])
    
    if processed_file is not None:
        processed_df = pd.read_csv(processed_file)
        
        if 'source_dataset' not in processed_df.columns:
            st.error("ã‚¨ãƒ©ãƒ¼: ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯åˆ†å‰²ç”¨ã®æƒ…å ±ï¼ˆ'source_dataset'åˆ—ï¼‰ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        else:
            original_filenames = processed_df['source_dataset'].unique()
            
            st.success("ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²æº–å‚™ãŒã§ãã¾ã—ãŸã€‚")
            
            ### --- æ”¹å–„ç‚¹: DRYåŸå‰‡ã«æ²¿ã£ã¦ã‚³ãƒ¼ãƒ‰ã‚’ãƒ«ãƒ¼ãƒ—å‡¦ç†ã« --- ###
            cols = st.columns(len(original_filenames))
            for i, filename in enumerate(original_filenames):
                with cols[i]:
                    df_processed = processed_df[processed_df['source_dataset'] == filename].copy()
                    df_processed.drop(columns=['source_dataset'], inplace=True)
                    
                    st.subheader(f"åŠ å·¥å¾Œã®ãƒ‡ãƒ¼ã‚¿: {filename}")
                    st.dataframe(df_processed.head())
                    st.download_button(
                       label=f"åŠ å·¥å¾Œã® {filename} ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                       data=convert_df_to_csv(df_processed),
                       file_name=f"processed_{filename}",
                       mime='text/csv',
                       key=f"download_button_{i}" # ãƒœã‚¿ãƒ³ã”ã¨ã«ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚­ãƒ¼ã‚’è¨­å®š
                    )
